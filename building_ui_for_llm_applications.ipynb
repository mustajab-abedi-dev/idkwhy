{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mustajab-abedi-dev/idkwhy/blob/main/building_ui_for_llm_applications.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-genai"
      ],
      "metadata": {
        "id": "7HC0b44LdheT",
        "collapsed": true,
        "outputId": "1092029d-2426-4e7d-ad7d-2df1508478a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.62.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai) (2.47.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (9.1.3)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E3MHlMptTSlE",
        "outputId": "25a0447c-62e9-474c-e2c5-7341482ee5ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excellent question, and a fundamental one in contemporary Artificial Intelligence. Let us meticulously deconstruct the concept of Large Language\n"
          ]
        }
      ],
      "source": [
        "from google import genai\n",
        "from google.colab import userdata\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=userdata.get(\"GEMINI_API_KEY\"))\n",
        "\n",
        "personalities = {\n",
        "  \"Friendly\":\n",
        "  \"You are a friendly, enthusiastic, and highly encouraging Study Assistant. Your goal is to break down complex concepts into simple, beginner-friendly explanations. Use analogies and real-world examples that beginners can relate to. Always ask a follow-up question to check understanding\",\n",
        "  \"Academic\":\n",
        "  \"You are a strictly academic, highly detailed, and professional university Professor. Use precise, formal terminology, cite key concepts and structure your response. Your goal is to break down complex concepts into simple, beginner-friendly explanations. Use analogies and real-world examples that beginners can relate to. Always ask a follow-up question to check understanding\"\n",
        "}\n",
        "\n",
        "def study_assistant(question, persona):\n",
        "    system_prompt = personalities[persona]\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        config=types.GenerateContentConfig(\n",
        "            system_instruction=system_prompt,\n",
        "            temperature=0.4,\n",
        "            max_output_tokens=600\n",
        "        ),\n",
        "        contents=question\n",
        "    )\n",
        "    return response.text\n",
        "\n",
        "question = \"What are LLMs?\"\n",
        "personality = \"Academic\"\n",
        "print(study_assistant(question, personality))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio\n"
      ],
      "metadata": {
        "id": "GDSL7WhbdkQ7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.colab import userdata\n",
        "\n",
        "client = genai.Client(api_key=userdata.get(\"GEMINI_API_KEY\"))\n",
        "\n",
        "personalities = {\n",
        "  \"Friendly\":\n",
        "  \"\"\"You are a friendly, enthusiastic, and highly encouraging Study Assistant.\n",
        "  Your goal is to break down complex concepts into simple, beginner-friendly explanations.\n",
        "  Use analogies and real-world examples that beginners can relate to.\n",
        "  Always ask a follow-up question to check understanding\"\"\",\n",
        "  \"Academic\":\n",
        "  \"\"\"You are a strictly academic, highly detailed, and professional university Professor.\n",
        "  Use precise, formal terminology, cite key concepts and structure your response.\n",
        "  Your goal is to break down complex concepts into simple, beginner-friendly explanations.\n",
        "  Use analogies and real-world examples that beginners can relate to.\n",
        "  Always ask a follow-up question to check understanding\"\"\"\n",
        "}\n",
        "\n",
        "def study_assistant(question, persona):\n",
        "    system_prompt = personalities[persona]\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        config=types.GenerateContentConfig(\n",
        "            system_instruction=system_prompt,\n",
        "            temperature=0.4,\n",
        "            max_output_tokens=2000\n",
        "        ),\n",
        "        contents=question\n",
        "    )\n",
        "    return response.text\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=study_assistant,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=4, placeholder=\"Ask a question...\", label=\"Question\"),\n",
        "        gr.Radio(choices=list(personalities.keys()), value=\"Friendly\", label=\"Personality\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(lines=10, label=\"Response\"),\n",
        "    title=\"Study Assistant\",\n",
        "    description=\"Ask a question and get an answer from your AI study assistant with a chosen personality.\",\n",
        "    theme = \"monochrome\"\n",
        ")"
      ],
      "metadata": {
        "id": "VzjYQE-pUntB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "ZM28zjWFUpLf",
        "outputId": "6d139a17-a213-455a-c29f-4e88e00a68ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://1e595b8badc4292328.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1e595b8badc4292328.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://1e595b8badc4292328.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LfwKkdTdUons"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}